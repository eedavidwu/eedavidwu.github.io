<!DOCTYPE HTML>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Haotian Wu</title>
  
  <meta name="author" content="Haotian Wu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/imperial.JPG">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr style="padding:0px">
    <td style="padding:0px">
	
	<!--Profiles-->	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		
		<tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Haotian Wu</name>
              </p>
        <p>
			  Hello! This is Haotian Wu. I am a PhD student in <a href="https://www.imperial.ac.uk/electrical-engineering/">Imperial College London</a>, supervised by  <a href="https://www.imperial.ac.uk/people/d.gunduz"> Prof. Deniz Gunduz</a> and <a href="https://www.imperial.ac.uk/people/k.mikolajczyk"> Prof. Krystian Mikolajczyk</a>. 
        </p>
			  <p>        
        I got my Bachelor and Master degree in Electrical Engineering at <a href="http://www.zju.edu.cn/english/">Zhejiang University</a>, supervised by  <a href="https://scholar.google.com/citations?user=ic9y2dIAAAAJ&hl=zh-CN">Prof. Zhiyun Lin</a> and <a href="https://scholar.google.com/citations?hl=en&user=rgwDYosAAAAJ&view_op=list_works&sortby=pubdate"> Prof. Ji Xiang</a>. 
				</p>
				<p>
				I was also awarded Master Degree in Control Systems at <a href="https://www.imperial.ac.uk/electrical-engineering/research/control-and-power/">Imperial College London</a> in 2018, supervised by <a href="https://www.imperial.ac.uk/people/r.vinter">Prof. Richard Vinter</a> and <a href="http://www.imperial.ac.uk/people/a.astolfi">Prof. Alessandro Astolfi</a>.
        </p>
        <p>
          I'm interested in machine learning for communication, control theory, and computer vision. Some of my recent research works are listed as:

        </p>
              <p style="text-align:center">
                <!--<a href="mailto:haotianwu@zju.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/CV_wht.pdf">CV</a> &nbsp/&nbsp
                <a href="data/haotianwu-bio.txt">Biography</a>&nbsp/&nbsp
				        <a href="http://eedavidwu.github.io">Blog</a> &nbsp/&nbsp
                <a href="https://github.com/eedavidwu/">Github</a> &nbsp-->
                <!--<a href="http://www.linkedin.com/in/jonathanbarron/"> LinkedIn </a>-->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
			   <img style="width:100%;max-width:100%" alt="profile photo" src="images/wht_circle.jpg" class="hoverZoomLink">

              <!-- <a href="images/My_cat.jpg"> <img style="width:100%;max-width:100%" alt="profile photo" src="images/me_circle.jpg" class="hoverZoomLink"></a> -->
            </td>
			
			 
          </tr>
		  </tbody>
        </table>



     <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
          <tr bgcolor="#ffffd0">
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Journal</heading>
              </td>
          </tr>
         </tbody>
       </table>
       	<!--Papers-->			
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>       
          <!--Fishery paper-->
          <tr onmouseout="fish_stop()" onmouseover="fish_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <div class="two" id='fish_image'><img src='images/WCL_EI.png'></div>
                      <img src='images/WCL_EI.png'>
                    </div>
                    
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    
                      <papertitle><font color='#0066CC'>Collaborative Semantic Communication for Edge Inference
                      </font></papertitle>
      
                    <br>
                    Wing Fei Lo, Nitish Mital, <strong>Haotian Wu*</strong>, Deniz Gündüz.
                    <br>
                    <em>IEEE Wireless Communications Letters </em>, 2023
              <br>
                    <a href="https://ieeexplore.ieee.org/document/10066513">Paper</a> /
                    <a href="https://github.com/eedavidwu/">Code</a>
                    <p>
                      We propose novel deep learning-based joint source and channel coding (JSCC) schemes for the collaborative image retrieval problem at the wireless edge, which are shown to outperform the single-device JSCC and the separation-based multiple-access benchmarks. 
                    </p>
                  </td>
            </tr>
            <!--CA-JSCC paper-->
            <tr onmouseout="fish_stop()" onmouseover="fish_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='fish_image'><img src='images/WCL_OFDM.png'></div>
                  <img src='images/WCL_OFDM.png'>
                </div>
                
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                
                  <papertitle><font color='#0066CC'>Channel-Adaptive Wireless Image Transmission with OFDM
                  </font></papertitle>
  
                <br>
                <strong>Haotian Wu*</strong>, Yulin Shao, Krystian Mikolajczyk, Deniz Gündüz
                <br>
                <em>IEEE Wireless Communications Letters </em>, 2022
                <br>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9878262">Paper</a> /
                    <a href="https://github.com/eedavidwu/">Code</a>
                    <p>
                      We present a dual-attention based channel-adaptive joint source and channel coding (CA-JSCC) scheme for wireless image transmission over multipath fading channels, which is adaptive to channel-gain and noise-power variations. 
                    </p>
                  </td>
              </tr>
          </table>
<p>
<br>
</p>
                           
	<!--Papers-->			
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>

     <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr  bgcolor="#FFF8D7">
          <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Conference</heading>
              </td>
          </tr>
         </tbody>
    </table>

	<!--Papers-->			
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>
      
    
      <!--ICC paper-->
		 <tr onmouseout="filter_stop()" onmouseover="filter_start()" bgcolor="#FFF8D7">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='filter_image'><img src='images/ICC_MIMO.png'></div>
          <img src='images/ICC_MIMO.png'>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
       
          <papertitle><font color='#0066CC'>Vision Transformer for Adaptive Image Transmission over MIMO Channels</font></papertitle>

        <br>
        <strong>Haotian Wu*</strong>, Yulin Shao, Chenghong Bian, Krystian Mikolajczyk, Deniz Gündüz
        <br>
        <em>IEEE International Conference on Communications (ICC), </em> 2023; <strong>Awarded Best paper</strong>

        <br>
        <a href="https://scholar.google.com/citations?hl=en&user=tA7ECRUAAAAJ">Paper</a> /
        <a href="https://github.com/eedavidwu/">Code</a>

        <p>
          This paper presents a vision transformer (ViT) based JSCC scheme for wireless image transmission over MIMO systems, called ViT-MIMO, which exploits the self-attention mechanism to adaptively learn the feature mapping and power allocation based on the source semantics and channel conditions. 
           </p>
      </td>
   </tr>

      <!--SPAWC paper-->
      <tr onmouseout="filter_stop()" onmouseover="filter_start()" bgcolor="#FFF8D7">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='filter_image'><img src='images/SPAWC_EI.png'></div>
            <img src='images/SPAWC_EI.png'>
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
         
            <papertitle><font color='#0066CC'>Features-over-the-Air: Contrastive Learning Enabled Cooperative Edge Inference</font></papertitle>
  
          <br>
          <strong>Haotian Wu*</strong>, Nitish Mital, Krystian Mikolajczyk, Deniz Gündüz
          <br>
          <em> </em> 2023; 
  
          <br>
          <a href="https://scholar.google.com/citations?hl=en&user=tA7ECRUAAAAJ">Paper</a> /
          <a href="https://github.com/eedavidwu/">Code</a>
  
          <p>
            We study the collaborative image retrieval problem and propose a semantic NOMA communication paradigm, where the channel inputs mapped from extracted features are added over-the-air. 
            A novel contrastive learning based semantic communication paradigm is proposed to exploit signal correlations and maximize the retrieval accuracy under a total bandwidth constraints. 
          </p>
        </td>
     </tr>

    

		   
		<!--Fishery paper-->
		<tr onmouseout="fish_stop()" onmouseover="fish_start()" bgcolor="#FFF8D7">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='fish_image'><img src='images/fish_new.jpg'></div>
                <img src='images/fish_new.jpg'>
              </div>
              <script type="text/javascript">
                function fish_start() {
                  document.getElementById('fish_image').style.opacity = "1";
                }

                function fish_stop() {
                  document.getElementById('fish_image').style.opacity = "0";
                }
                fish_stop()
				
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle><font color='#0066CC'>Fishery monitoring system with AUV based on YOLO and SGBM</font></papertitle>

              <br>
              <strong>Haotian Wu</strong>, Shimin He, Zejun Deng, et al.
              <br>
              <em>The 38th Chinese Control Conference (CCC) </em>, 2019
			  <br>
              <a href="https://ieeexplore.ieee.org/document/8866087">Paper</a> /
              <a href="https://github.com/eedavidwu/yolov3">YOLO darknet code</a> /
              <a href="https://github.com/eedavidwu/HED_pytorch">HED-net pytorch code</a> 
              <p>
			  This fishery monitoring system detects the fishes by YOLOv3 and predicts the depth map with SGBM to estimate the size of the fishes. This system is efficient and real-time compared with the manual method or dual-frequency sonar.
			  </p>
            </td>
         </tr>
		 
		 <!--filter paper-->
		 <tr onmouseout="filter_stop()" onmouseover="filter_start()" bgcolor="#FFF8D7">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='filter_image'><img src='images/bearing_range_error.jpg'></div>
                <img src='images/bearing_range_tracking.jpg'>
              </div>
              <script type="text/javascript">
                function filter_start() {
                  document.getElementById('filter_image').style.opacity = "1";
                }

                function filter_stop() {
                  document.getElementById('filter_image').style.opacity = "0";
                }
                filter_stop()
				
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
             
                <papertitle><font color='#0066CC'>Hypothetical Analytic Filter for the tracking with bearing and range mixture measurements</font></papertitle>

              <br>
              <strong>Haotian Wu</strong>, Ji Xiang.
              <br>
              <em>The 31th Chinese Control and Decision Conference (CCDC) </em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8832333">Paper</a> 
              <p>
			  This nonlinear filter uses the bearing information first to overcome the bimodal problem, and then use the range information to correct the performance. The lower computation demand and its robust convergence are two main advantages.
			  </p>
            </td>
         </tr>
		 
		 
		<!--4th ccc cnn paper-->
		 <tr onmouseout="wind_stop()" onmouseover="wind_start()" bgcolor="#FFF8D7">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='wind_image'><img src='images/wind_pre.jpg'></div>
                <img src='images/wind_result.jpg'>
              </div>
              <script type="text/javascript">
                function wind_start() {
                  document.getElementById('wind_image').style.opacity = "1";
                }

                function wind_stop() {
                  document.getElementById('wind_image').style.opacity = "0";
                }
                wind_stop()
				
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle><font color='#0066CC'>A Novel Method for Detection of Wind Turbine Blade Imbalance Based on Multi-Variable Spectrum Imaging and Convolutional Neural Network</font></papertitle>
              
              <br>
              Zhe Cao, Jian Xu, Wei Xiao, Yanjing Gao and <strong>Haotian Wu</strong>.
              <br>
              <em>The 38th Chinese Control Conference (CCC)</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8865600">Paper</a> 
              
      <p>
			This paper presents a novel method used for detecting wind turbine blade imbalance with high accuracy. Generator speed, torque and X acceleration were processed into combined spectral images with 'Fourier transform', which were then fed into CNN model to extract the fault features. 
      </p> 
            </td>
      </tr>
		

		</tbody>  
		</table>

<p>
<br>
</p>

<p>
<br>
</p>

<!--Project -->
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>
            <tr bgcolor="#FFF8D7">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects</heading>
              <p>
                During my bachelor and master study period time, I did many projects in robotics and computer vision. 
				</p>
            </td>
          </tr>
		  </tbody>
		</table>
        

	<!--Projetcs_list-->		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>


    <!--1st- Project: defect-->
    <tr onmouseout="defect_stop()" onmouseover="defect_start()" bgcolor="#ECF5FF">
    
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='defect_image'><img src='images/defect_dec_show.jpg'></div>
                <img src='images/defect_dec_net.jpg'>
              </div>
              <script type="text/javascript">
                function defect_start() {
                  document.getElementById('defect_image').style.opacity = "0";
                }

                function defect_stop() {
                  document.getElementById('defect_image').style.opacity = "1";
                }
                defect_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle><font color='#0066CC'>Semi-supervised industrial inspection of tire quality </font></papertitle>
              <br>
              <strong>Haotian Wu</strong>
              <br>
              <em>Huawei Research Institute, Cloud & AI Group</em>, &nbsp; 2020.04 - 2020.10
              <br>
              
              <p>
        To replace manual detection with AI in the industrial inspection of tire quality, unbalanced datasets and lots of detection noises are main challenges. 
        </p>
              <p>

        I develop a novel GAN-based Semi-supervised method, which only use the positive dataset to detect the defect. Also meta-learning and few shot learning are used for new version.
        </p>
        
            </td>
          </tr>
		
		<!--2nd- Project: SLAM and USV-->
		  
		<!--2nd- Project: worker-->
		<tr onmouseout="worker_stop()" onmouseover="worker_start()" bgcolor="#ECF5FF">
		
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='worker'><img src='images/heat_map.jpg'></div>
                <img src='images/worker.jpg'>
              </div>
              <script type="text/javascript">
                function worker_start() {
                  document.getElementById('worker').style.opacity = "1";
                }

                function worker_stop() {
                  document.getElementById('worker').style.opacity = "0";
                }
                worker_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle><font color='#0066CC'>Safety monitoring of construction scene</font></papertitle>

              <br>
              <strong>Haotian Wu</strong>
              <br>
              <em>Huawei Research Institute, Cloud & AI Group</em>,  &nbsp; 2019.06 - 2019.09
              <br>
              <p>
			  This project is to do small object detection on workers and classification on their wearing. 
			  I use the yolov3 and multi-task resnet34 as the baseline to detect whether workers wearing safety helmet and safety clothes. 
			  </p>
			  <p>
			  Besides, I draw the heatmap and add some constrains on the attention of the network to make higher mAP. This net has a mAP with 71% in workers' detection and 91% accracy with classification of their wearing.
				</p>
			</td>
          </tr>
		  
          <!--4th- Project: mobile robot-->
		<tr onmouseout="mobile_stop()" onmouseover="mobile_start()" bgcolor="#ECF5FF">
		
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mobile_image'><img src='images/car_cor.jpg'></div>
                <img src='images/mobile.jpg'>
              </div>
              <script type="text/javascript">
                function mobile_start() {
                  document.getElementById('mobile_image').style.opacity = "1";
                }

                function mobile_stop() {
                  document.getElementById('mobile_image').style.opacity = "0";
                }
                mobile_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle> <font color='#0066CC'> Navigation and Motion Control of Vision based Mobile Robot </font></papertitle>
             
              <br>
              <strong>Haotian Wu</strong>
              <br>
              <em>Zhejiang University</em>, 2017
              <br>
			  <a href="https://github.com/eedavidwu/Mobile_robot_interface/">code</a>
              <p>
			  This project researches on the navigation and motion control of mobile robot based on vision and IMU.
				</p>
			<p>
			  The main work in this project includes: hardware design, obtaining the location of mobile robot, control algorithm, correction of motion deviation, path planning and human-computer interaction.
				</p>
            </td>
          </tr>
		  
		</tbody>
	     </table>
	



             <p>
          <br>
				</p>
 
		

<!--Patents part-->		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>
           <tr bgcolor="#F0FFF0">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patents</heading>

            </td>
            </tr>
		</tbody>
        </table>
		
	<!--Patents List-->		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>

		<!--1st patent-->
		<tr bgcolor="#F0FFF0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/coor_robot.jpg'>
            </td>
			
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle><font color='#0066CC'>Cooperative System of Indoor Mobile Robot Based on QR code and Fuzzy Algorithm</font></papertitle>
              <br>
              <strong>Haotian Wu</strong>, Kaijian Liu, Tianchen Zhang, &nbsp; &nbsp; Status: <strong> Patented</strong>
			  <br>Patent ID: No.201610964289.8
			  <br>
              <a href="./data/201610964289.8.jpg"> Authorization Document</a> /
			  <a href="http://www2.soopat.com/Patent/201610964289">Patent Information</a>
              <p>
			  The invention proposes an indoor multi-mobile robot cooperation system.  The path planning is based on QR-code. The motion correction is based on fuzzy PID.
			  </p>
			  <p>
			  The system has low positioning cost and can realize efficient path planning, which makes multi-robots work together, avoid conflicts and work efficient.
			  </p>
            </td>
		</tr>
		
		<!--2nd patent-->
		<tr bgcolor="#F0FFF0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/algri_robot.jpg'>
            </td>
			
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle><font color='#0066CC'>Agricultural mobile robot based on Random Forest</font></papertitle>

              <br>
              Zhiyun Lin, <strong>Haotian Wu</strong>, Junjie Liu, &nbsp; &nbsp; Status: &nbsp; <strong> Patented</strong> 
			  <br>Patent ID: No. 201710367405.2
			  <br>
			
              <a href="./data/201710367405.2.jpg"> Authorization Document</a> /
              <a href="http://www2.soopat.com/Patent/201710367405">Patent Information</a>
              
              <p>The invention proposes a mobile robot based on random forest and QR-code. The robot uses QR code for localization and predicts the opration by random forest.</p>
			  <p>The goal of the robot is to achieve agricultural automation and reduce manual participation.</p>
			</td>
		</tr>
		
        
		<!--3rd patent-->
	<tr bgcolor="#F0FFF0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/water_saving.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle><font color='#0066CC'>Smart Water-saving Faucet Based on Neural Network and SCM</font></papertitle>
              <br>
              <strong>Haotian Wu</strong>, &nbsp; &nbsp; &nbsp; &nbsp; Status: <strong> Patented</strong>
			  <br>Patent ID: No.201610135909.7
              <br>
              <a href="./data/2016101359097.jpg"> Authorization Document</a> /
              <a href="http://www2.soopat.com/Patent/201610135909">Patent Documents</a>
              <p>The invention proposes an intelligent water-saving faucet based on neural network. This faucet can predict the needs of water temperature and meet people's needs quickly without realeasing too much cold water, which can avoid the waste of water resources  .</p>
            
			  </td>
		</tr>

		
		<!--4th patent-->
	<tr bgcolor="#F0FFF0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/self_corre.jpg'>
            </td>
			
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle><font color='#0066CC'>Self-correction algorithm based on attitude detection and special landmark</font></papertitle>
              <br>
              Zhiyun Lin, <strong>Haotian Wu</strong>, Kaijian Liu,&nbsp; &nbsp; Status: <strong> Patented</strong>
			  <br>Patent ID: No.201710378237.7
			  <br>
			  
              <a href="./data/201710378237.7.jpg"> Authorization Document</a> /
			  <a href="http://www2.soopat.com/Patent/201710378237">Patent Information</a>
              <p>The invention proposes a mobile robot based on random forest and QR-code. The robot uses QR code for localization and predicts the opration by random forest.</p>
			  <p>The goal of the robot is to achieve agricultural automation and reduce manual participation.</p>
            </td>
		</tr>
		
				<!--5th patent-->
	<tr bgcolor="#F0FFF0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/patent_fisher.jpg'>
            </td>
			
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle><font color='#0066CC'>A fishery growth monitoring system</font></papertitle>
              <br>
              Ji Xiang, <strong>Haotian Wu</strong>,&nbsp; &nbsp; Status: <strong> Under effective examination</strong>
			  <br>Patent ID: No.202010436332.X
			  <br>
			  
              <a href="./data/patent_fishery.pdf"> Authorization Document</a> /
			  <a href="./data/patent_fishery.pdf">Patent Information</a>
              <p>The invention proposes a fishery growth monitoring system based on YOLO and SGBM. </p>
			  <p>The goal of the system is to predict and monitor the fishery growth situation.</p>
            </td>
		</tr>
		

        
		
				
		</tbody>
		</table>
             <p>
          <br>
				</p>
 
   
<!--Honour-->		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>
      <tr bgcolor="#FFF8D7">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards and Honors</heading>
              <p>
               <strong>National Scholarship for Postgraduate Student</strong> 
			  </p>
			  
           <p>
				</p>
			  
			  <p>
               <strong>		Excellent Postgraduate Students' Award in Zhejiang University</strong>
			 </p>
				
                <p>
               <strong>Postgraduate Studentship in Imperial College London </strong> 
				</p>
   
                <p>
				</p>
                <p>
               <strong>Outstanding undergraduate thesis in Zhejiang University</strong> 
				</p>
        
                <p>
				</p>
               
			   <p>
               <strong>The Scholarship for Academic Excellence in Zhejiang University</strong> 
				</p>
        
                        <p>
				</p>
                        <p>
               <strong>The Scholarship for Outstanding Students in Zhejiang University</strong> 
	
				</p>

            </td>
        </tr>
       </tbody>
	   </table> 

                <p>
          <br>
				</p>
	
<!--Reference-->		
        		 	
<!--Acknogement-->		
		


	
		 	
		</tbody>  
		</table>






	</td>
    </tr>
</tbody>
</table>
</body>
</html>
