<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content=>
  <meta name="keywords" content=>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>W2-DeepJSCC </title>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>


  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8RM5LWFPPP"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-8RM5LWFPPP');
  </script>

  <!-- <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet"> -->

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <!-- <link rel="stylesheet" href="./static/css/fontawesome.all.min.css"> -->
  <!-- <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"> -->
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    .section {
      padding-top: 1rem;
      padding-bottom: 1rem;
    }
  </style>
  <style>
    .image-container {
  text-align: center; /* Center aligns inline content within the container */
}

    .centered-image {
      display: block; /* Ensures the image behaves as a block element */
      margin: 0 auto; /* Auto margins horizontally center the image */
      max-width: 100%; /* Ensures the image does not exceed its container's width */
      height: auto; /* Allows the image to maintain its aspect ratio */
    }
    .video-container {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      gap: 1rem;
    }
    .video-container .video-small {
      width: 50%; /* 75% of 45% = 33.75% */
    }
    .video-container .video-large {
      width: 90%;
    }

  </style>

</head>
<body>


  <section class="hero" >
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 style="font-size: 39px" class="title is-1 publication-title">Realism and Fidelity: Two Sides of a Coin in <br>
              Deep Joint Source-Channel Coding
            </h1>
            <!--<h2 style="font-size: 25px" class="title is-1 publication-title cvpr">ICASSP 2024</h2>-->
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Haotian Wu, Weichen Wang, Di You, Pier Luigi Dragotti, and Deniz Gündüz</a></span>
            </div>
            <div class="is-size-6 has-text-grey" style="margin-top: 0.3em;">
              Imperial College London, Department of Electrical and Electronic Engineering
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://openreview.net/forum?id=5pcWOzIwCr#discussion/"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                <span class="link-block">
                  <a href="https://github.com/eedavidwu/"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    
                  </a>
                    </a>

                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" style="padding-top: 1rem; padding-bottom: 1rem;">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Deep joint source-channel coding (DeepJSCC) offers a promising approach to improving transmission efficiency by jointly leveraging source semantics and channel conditions. While prior work has focused on fidelity under varying channel conditions, recent diffusion-based approaches improve perceptual quality at the cost of high complexity and limited adaptability. In this work, we reveal that fidelity and perceptual realism can be unified in an adaptive DeepJSCC scheme through SNR-aware optimization, eliminating the need for separate models. Specifically, we propose \( \text{W}^2 \)-DeepJSCC, a unified, channel-adaptive framework that dynamically balances fidelity and perceptual realism based on channel conditions. It introduces two key innovations: a saliency-guided perception–fidelity adapter (SG-PFA) and wavelet Wasserstein distortion (WA-WD). SG-PFA enables a single model to adapt across varying channel conditions, preserving semantic realism under poor channel conditions while enhancing fidelity under good ones. WA-WD, inspired by foveal and peripheral vision, provides fine-grained control in the wavelet domain. As a plug-and-play module, \( \text{W}^2 \)-DeepJSCC integrates seamlessly with existing DeepJSCC architectures. Experiments show that \( \text{W}^2 \)-DeepJSCC significantly outperforms baselines in perceptual metrics while maintaining strong fidelity at high SNRs. Prototype verification further highlights its advantages, demonstrating that the proposed method delivers competitive fidelity and perception with low complexity, making it a promising alternative for future deployments. Additionally, a user study further confirms that WA-WD aligns more closely with human perception than existing metrics.

            </p>
          </div>
          <!-- <img src="static/architecture.png"> -->
        </div>
      </div>
    </div>

    </div>
  </section>

  <section class="moric-quote" lang="zh-CN" aria-label="MoRIC">
    <style>
      .moric-quote {
        margin: 2rem auto;
        padding: 1.5rem;
        max-width: 900px;
        background: #f2f2f2;
        border-left: 4px solid #e5a04b;
        font-family:
          "Noto Serif SC","Source Han Serif SC","Songti SC","STSong",
          "PingFang SC","Hiragino Sans GB","Noto Serif CJK SC",serif;
        font-style: italic;
        color: #333;
        line-height: 1.9;
        font-size: clamp(1rem, 1.8vw, 1.25rem);
      }
      .moric-quote blockquote {
        text-align: center;
        margin: 0;
      }
      

      .moric-quote cite {
        display: block;
        text-align: right;
        font-style: normal;
        color: #666;
        margin-top: 0.6rem;
      }
    </style>
  
    <blockquote>
      <p class="hero-question">
             Can a single DeepJSCC model adaptively balance <br/>
      fidelity and realism across various channel conditions?
    </p>

    </blockquote>
  </section>

  <section class="section" style="padding-top: 1rem; padding-bottom: 1rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-4 has-text-centered">Performance of \( \text{W}^2 \)-DeepJSCC.</h2>
  
            <div class="image-container">
              <img src="vis_example.png" alt="Visual comparison" style="max-width: 100%; height: auto;">
  
              <p class="has-text-centered" 
                 style="margin-top: 0.7rem; font-weight: 600; font-size: 1rem; max-width: 90%; margin-left: auto; margin-right: auto;">
  
                Fig. 1 Visual comparison between different schemes when SNR = 0 dB and \( R = 1/24 \). 
                \( \text{W}^2 \)-DeepJSCC achieves the best perceptual realism, 
                closely matching the original image.
              </p>
  
            </div>
  
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <section class="section" style="padding-top: 1rem; padding-bottom: 1rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-4 has-text-centered">Proposed WA-WD for all DeepJSCC schemes.</h2>
            <div class="image-container">
              <img src="Fig_2_wawd.png" alt="Description of the image" style="max-width: 100%; height: auto;">
              <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold; font-size: 1.0rem;">
                Fig. 2 A perceptually aligned optimization objective inspired by foveal/peripheral vision, providing fine-grained control over fidelity-realism in the wavelet domain.

              </p>
            </div>
           
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" style="padding-top: 1rem; padding-bottom: 1rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-4 has-text-centered">Proposed Saliency-Guided Perception–Fidelity Adapter.</h2>
            <div class="image-container">
              <img src="Fig_3_illu_sigma.png" alt="Description of the image" style="max-width: 65%; height: auto;">
              <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold; font-size: 1.0rem;">
                Fig. 3 An SNR-aware modulation mechanism for the proposed loss function that preserves perceptual realism at low SNR while gradually shifting toward high-fidelity reconstruction at high SNR.
              </p>
            </div>
           
          </div>
        </div>
      </div>
    </div>
  </section>
  

    <section class="section" style="padding-top: 1rem; padding-bottom: 1rem;">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <h2 class="title is-4 has-text-centered">Numerical results across various scenarios</h2>
              <div class="image-container">
                <img src="main_results.png" alt="Description of the image" style="max-width: 100%; height: auto;">
                <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold; font-size: 1.0rem;">
                  Fig. 4 Experimental resutls on Kodak dataset.
                </p>
              </div>
              <div class="image-container">
                <img src="wawd_bar.png" alt="Description of the image" style="max-width: 100%; height: auto;">
                <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold; font-size: 1.0rem;">
                  Fig. 5 User study to evaluate the human preference.
                </p>
              </div>
              <div class="image-container">
                <img src="vis_1.png" alt="Description of the image" style="max-width: 100%; height: auto;">
                <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold; font-size: 1.0rem;">
                  Fig. 6 Visual comparisons at SNR = 0 dB and R =1/24, where our method demonstrates clear advantages across the entire image. Additional examples are available in the paper.
                </p>
              </div>
              <div class="image-container">
                <img src="Prototype.png" alt="Description of the image" style="max-width: 100%; height: auto;">
                <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold; font-size: 1.0rem;">
                  Fig. 7 Prototype verification under different transmitter power for Kodak dataset, where the bandwidth ratio is 1/2. Proposed method offers a clear advantage, such as textures on trees and even interior details beneath the river surface that are lost in baseline reconstructions.
                </p>
              </div>
            </div>
    
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="BibTeX" style="padding-top: 1rem; padding-bottom: 1rem;">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre>
<code>
  @inproceedings{wu2025realism,
    title={Realism and Fidelity: Two Sides of a Coin in Deep Joint Source-Channel Coding},
    author={Wu, Haotian and Wang, Weichen and You, Di and Dragotti, Pier Luigi and Gunduz, Deniz},
    booktitle={NeurIPS 2025 Workshop: AI and ML for Next-Generation Wireless Communications and Networking}
  }
</code>
</pre>
      </div>
    </section>


    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This webpage template is adapted from <a
                  href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
                under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 License</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
    </div>


</body>

</html>
